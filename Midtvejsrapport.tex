\documentclass[11pt]{article}
\usepackage[a4paper, hmargin={2.8cm, 2.8cm}, vmargin={2.5cm, 2.5cm}]{geometry}
\usepackage{eso-pic} % \AddToShipoutPicture
\usepackage{graphicx} % \includegraphics
\usepackage{tabto}
\usepackage{enumerate}
\usepackage{txfonts}
\usepackage[utf8]{inputenc}

%% Change `ku-farve` to `nat-farve` to use SCIENCE's old colors or
%% `natbio-farve` to use SCIENCE's new colors and logo.
\def \ColourPDF {include/ku-farve}

%% Change `ku-en` to `nat-en` to use the `Faculty of Science` header
\def \TitlePDF   {include/ku-en}  % University of Copenhagen

\title{
  \vspace{3cm}
  \Huge{Midtvejsrapport} \\
  \Large{More elaborate subtitle}
}

\author{
  \Large{Bjarke Kingo Iversen}
  \\ \texttt{bjarkekingo50@gmail.com} \\\\
  \Large{Susanne Truong}
  \\ \texttt{suzze-t@hotmail.com}
}

\date{
    \today
}

\begin{document}

\AddToShipoutPicture*{\put(0,0){\includegraphics*[viewport=0 0 700 600]{\ColourPDF}}}
\AddToShipoutPicture*{\put(0,602){\includegraphics*[viewport=0 600 700 1600]{\ColourPDF}}}

\AddToShipoutPicture*{\put(0,0){\includegraphics*{\TitlePDF}}}

\clearpage\maketitle
\thispagestyle{empty}

\newpage
\section{Beskrivelse af det undersøgte problem}
Problemet er undersøgt ved at analysere, diskutere via. matematiske udledninger og argumenter, samt ved at implementere ngole af de egenskaber samt algoritmer der er relevante inden for Dijkstra, Bellmann Ford samt A*.
\section{Begrundede valg for metoder og værktøjer}
I og med at der særligt arbejdes med algoritmik er der af metode benyttet særligt matematisk deduktiv metode, hvoraf der ved præmisser og matematiske/geometriske lemmaer kan argumenteres til at nå en konklusion.\\
Af værktøjer er der brugt sproget C++ med dens tilhørende oversætter.\\
\section{Status og tidsplan}
\textbf{Indtil nu, har vi nået følgende:}\\
\begin{itemize}
\item 2. udkast af 'Introduction'
\item 'Problem definition'
\item 1. udkast af 'Notation'
\item 1. halvdel af 'On Shortest Paths'-afsnittet
\item 1. udkast til 'Proving correctness of shortest path algortihms'
\item 1. halvdel af 'Dijkstras algorithm'-afnsnittet
\item Startet på implementeringer
\end{itemize}
\textbf{Der mangler fortsat følgende:}\\
\begin{itemize}
\item 2. halvdel af 'On Shortest Paths'
\item 2. halvdel af 'Dijkstras algortihm'
\item Bellmann Ford
\item A*-star (Der er dog indtil nu gjordt mange teoretiske overvejelser om denne)
\item Implementering
\end{itemize}
\newpage
\textbf{Løs tidsplan:}\\
\begin{itemize}
\item 17. April: Implementering + Rapport
\item 24. April: Implementering + Rapport
\item 31. April: Implementering + Rapport
\item ...
\item Slut maj: Endelig rapport + benchmarking
\item 13. Juni: Aflevering af rapport
\item 22-23. Juni: Forsvar
\end{itemize}
\section{Relevant literature}
\begin{itemize}
\item Nils J. Nilsson, \textit{Principles of Artificial Intelligence}, Stanford University, Morgan Kaufmann Publishers, Inc. 1980

\item Cormen, T. H., Leiserson, C. E., Rivest, R. L., Stein, C., \textit{Introduction to Algorithms}, 3rd edition, MIT Press, 2009

\item E. W. Dijkstra, \textit{A Note on Two Problems in Connexion with Graphs}, \\ http://www-m3.ma.tum.de/foswiki/pub/MN0506/WebHome/dijkstra.pdf, 1959

\item Melissa Yan, \textit{Dikjkstra's algorithm (slides)}, \\ http://math.mit.edu/~rothvoss/18.304.3PM/Presentations/1-Melissa.pdf, 2014

\item Amit J Patel, \textit{Introduction to A*}, \\ http://theory.stanford.edu/~amitp/GameProgramming/AStarComparison.html, 2016

\item Nick Bruun, \textit{Easy C++ benchmarking}, \\ https://bruun.co/2012/02/07/easy-cpp-benchmarking, 2012

\item \textit{Shortest Paths: 6.006 Intro to Algorithms, Recitation 14. MIT}, \\ http://courses.csail.mit.edu/6.006/spring11/rec/rec14.pdf,  March 30 2011

\item Ashley Montanaro, \textit{COMS21103: Priority queues and Dijkstra’s algorithm}, University of Bristol \\ https://www.semanticscholar.org/paper/Priority-Queues-and-Dijkstra-s-Algorithm-Montanaro/8211695142f5178afed318dbd77fe688022fa7cf, 29 October 2013
\end{itemize}
\newpage
\begin{center}
\Huge{FORELØBIG RAPPORT}
\end{center}
\newpage
%% Write your dissertation here.
\section{Abstract}
\newpage
\tableofcontents
\newpage
\section{Introduction}
It is widely known that it can be time-consuming to choose the wrong path, if you want to travel from one city to another. It will most certainly be faster to aboard the train from Chicago to Seattle, rather than going through Los Angeles before heading to Seattle. Choosing the right path will therefore save a lot of time.\\
The problem herein is that its in lots of cases is nowhere intuitive which path that guarantees the consumation of time to be minimal. We probably can't withstand the big amounts of information if we should compute the shortest path, through millions of combinations by ourselves. For computersystems to choose such a path, they'd need a method for calculating such, an algorithm.\\
Different shortest-path algorithms are known to solve such problems theoretically. We'll examine the theory behind these, and analyse the complexity to see whether the time-complexity given by Bellmann-Ford and Dijkstras algorithms holds in real life implementations, by implementing them with both a binary and a fibonacci-heap in C++, thus finally to match them all up against each other.\\
We'll as well analyse and implement the A*-algorithm to see how well dijkstra match up against this on euclidean planar graphs. Since we're primarily interested in road-maps, we won't consider negative weights.\\

\section{Problem definition}
To examine and benchmark the complexity of different shortest-path algorithms, e.g. Dijkstra, Bellmann-Ford, and A* Search. We will do this by implementing and comparing them using different data structures and libraries. Finally we will compare the results of these experiments with the theoretical bounds.

\section{Notation}
A short list of notations used throughout the thesis:\\
\begin{itemize}
\item $G(V,E)$ = Graph, consisting of set of vertices V, and set of edges E
\item $s$ = Designated to be the source vertex s
\item $w(u,v)$ = Weighted distance from vertix u to v
\item $d[v]$ = The weigth of the current shortest path from s to v. $d[v]$ is initlized to be $\infty$ for all vertices besides the source vertex. $d[s]$ is initialized to be 0.
\item $\pi[v]$ = Predecessor/parent vertex to v in the current shortest path. $\pi[v]$ is initialized to be NIL. This is set to a vertex once/if a path is discovered from s to v.
\item $\delta(u,v)$ = the weigth of the shortest path from u to v.
 
\end{itemize}
\section{On Shortest Paths}
In the shortest path problem, a graph $G = (V,E)$ is given, where $V$	
is the set of vertices, and $E$ is the set of edges. Each edge
connects two vertices and contains a weight, indicating the cost of
moving between these vertices. By using a shortest path algorithm, we
can find a shortest path $P = {v_{1}, v_{2}, ..., v_{k}} \in V$ from a
given source vertex $s \in V$ to all other vertices $v \in V$. I.e.,
we want to find a path, where the total weight of the visited edges is
minimal.\\

\noindent
\textbf{Relaxation}\\
When searching for the shortest path from a source vertex $s$ to a
vertex $v$, a shortest-path estimate $d[v]$ is preserved for each
vertex $v \in V$. At first, $d[v]$ will be an overestimate, but if we see that the shortest path to $v$ can be improved by going through a vertex $u$, we update the estimate $d[v]$ with the new and lower cost. As better paths are found, we will eventually get the correct estimate and find the shortest path, if it exists. This technique is called relaxation and is used by the three algorithms that we will talk about later. The pseudocode for relaxing an edge $(u,v) $ is shown below:\footnote{Introduction to Algorithms, pg. 649}\\

%\noindent
\textbf{RELAX$(u, v, w)$}
\begin{enumerate}
\NumTabs{24}
\setlength\itemsep{0em}
\item \textbf{if } $d[v] > d[u] + w(u,v)$
\item \tab{$d[v] = d[u] + w(u,v)$}
\item \tab{$\pi[v] = u$}
\end{enumerate}
(explain the pseudocode :) )\\

\noindent
(Dry run relaxation of an edge? One in which a shortest- path estimate decreases and one in which no estimate changes... -> see pg. 649)\\

\section{Proving the correctness of shortest path algorithms}
The shortest path algorithms that we have talked about will always find a shortest path, if it exists. This can be proved by looking at the properties that shortest paths and relaxation have:\footnote{Introduction to Algorithms, pg. 650}

\begin{itemize}
\item \textbf{Triangle inequality}\\
The triangle inequality lemma is a geometric property of triangles which states that the sum of two lengths of any two sides must be greater than or equal to the remaining side. That is, for any triangle with sides $\{x,y,z\}$, we have that $z \leq x+y$.\\\\
Applied to the shortest path problem we have that for any edge $(u,v) \in E$, we have $\delta(s,v)\leq \delta(s,u) + w(u,v)$ (\textbf{Lemma 1}). Thus the shortest path from s to v must be less than or equal to the shortest path from s to u added to the weigth from u to v.\\
\item \textbf{Upper-bound property}\\
The upper-bound property says that our estimate for the shortest distance to v is always greater than or equal to the actual shortest path from s to v, for all vertices v$\in$ V.\\\\
That is $\forall v \in V.(d[v]\geq \delta(s,v))$. Once our estimate holds the actual value for the shortest path, the estimate never changes (\textbf{Lemma 2}).\\
\item \textbf{No-path property (\textbf{Corollary to Lemma 2})}\\
If there is no path from s to v, then we always have $d[v] = \delta(s,v) = \infty$.\\
\item \textbf{Convergence property}\\
The convergence property ensures us that if we from s, at sometime has u to v is the shortest path in G for some u,v $\in$ V, and if the estimated shortest path to u actually is the shortest path, we'd then have (prior to relaxing the edge (u,v)) that the estimated shortest path to v must be the shortest path to v at all times afterward.\\\\
That is, if $s\rightsquigarrow u\rightarrow v$ is a shortest path, and if $d[u] = \delta(s,u)$, then $d[v] = \delta(s,v)$ is assured at all time afterward (\textbf{Lemma 3}).\\
\item \textbf{Path-relaxation property}\\
Our path-relaxation property ensures that the relaxation of a shortest path p will derive that the distance to the k'th vertix in p is equal to the shortest path to vertix k.\\\\
Let $p = \{v_{1}, v_{2},\cdots ,v_{k}\}$ be a shortest path that goes from $v_{1}$ to $v_{k}$. If the edges are relaxed in the order $(v_{1},v_{2}), (v_{2},v_{3}), \cdots , (v_{k-1}, v_{k})$, then $d[v_{k}] = \delta(s,v_{k})$ once the whole path is relaxed \footnote{Shortest Paths: 6.006 Intro to Algorithms, March 30 2011, Recitation 14. MIT}(\textbf{Lemma 4}).\\
\item \textbf{Predecessor-subgraph property}\\
The predecessor-subgraph/parent-subgraph property ensures that once the shortest path to v is computed for all vertices v, the predecessor subgraph is a shorted-paths tree rooted at s.\\\\
Such that once $\forall v \in V.(d[v] = \delta(s,v))$ the predecessor subgraph that contains all the vertices with a finite distance from s, but with only edges that connects v to $\pi[v]$ is a shortest-path tree\footnote{Shortest Paths: 6.006 Intro to Algorithms, March 30 2011, Recitation 14. MIT} (\textbf{Lemma 5}).
\end{itemize}
\section{Bellmann-Ford algorithm}
...\\
If there is a negative cycle, the cost of the shortest path is decreased every time the algorithm runs through the negative cycle. By doing this numerous times, we can receive arbitrarily negative weights, thus making the cost undefined.
\section{Dijkstra's algorithm}
DER SKAL FORKLARES OM HOBS OG SÅDAN NOGET!
Dijkstra's algorithm takes a weighted graph $G = (V, E)$ and finds the shortest path from a single source to each other vertex in the graph.\\   

\noindent
\textbf{Assumptions}\\
For Dijkstra's algorithm to work, we must assume that the graph contains no negative weights. If there is a negative-weighted edge somewhere, the algorithm may find a wrong shortest-path as it won't necesarrily visit to relax the negative edge. This is due to dijkstra utilizing the greedy property of \textbf{Lemma 1}, thus that $\forall (u,v) \in E.(w(u,v) \geq 0)$


\noindent
(\textbf{Does the graph have to be connected???}\\
A connected graph means that for all $v \in V $,a vertex $v$ will be reachable from another vertex $w$ through an edge. If the graph is disconnected, some vertices will be unreachable, thus making some shortest paths infinite, if we try to reach these vertices.)\\\\

http://stackoverflow.com/questions/13159337/why-doesnt-dijkstras-algorithm-work-for-negative-weight-edges\\

http://stackoverflow.com/questions/20123076/can-dijkstras-single-source-shortest-path-algorithm-dectect-an-infinite-cycle-i\\

\noindent
\textbf{How Dijkstra's algorithm work}:\\
The pseudocode for Dijkstra's algorithm can be seen below:\footnote{Introduction to Algorithms, pg. 658}\\


\textbf{DIJKSTRA$(G, w, s)$}
\begin{enumerate}
\NumTabs{24}
\setlength\itemsep{0em}
\item INITIALIZE-SINGLE-SOURCE$(G, s)$
\item $S = \O$
\item $Q = G.V$
\item $\textbf{while } Q \neq \O$
\item \tab{$u = $ EXTRACT-MIN$(Q)$}
\item \tab{$S = S \cup \{u\}$}
\item \tab{\textbf{for} each vertex $v \in G.Adj[u]$}
\item \tab{}\tab{RELAX$(u,v,w)$}
\end{enumerate}

\noindent
\\
(write explanation of pseudocode and dry run an example? :))


We are only interested in finding a single target, so we have modified the original pseudocode for Dijkstra's algorithm:\\ 
\textbf{MODIFIED-DIJKSTRA$(G, w, s, t)$}
\begin{enumerate}
\NumTabs{24}
\setlength\itemsep{0em}
\item INITIALIZE-SINGLE-SOURCE$(G, s)$
\item $S = Q = {s}$
\item $\textbf{while } Q \neq \O$
\item \tab{$u = $ EXTRACT-MIN$(Q)$}
\item \tab{\textbf{if ko ko ko}}
\item \tab{$S = S \cup \{u\}$}
\item \tab{\textbf{for} each vertex $v \in G.Adj[u]$}
\item \tab{}\tab{RELAX$(u,v,w)$}
\end{enumerate}

The pseudocode now also takes a parameter $t$, indicating the target we want to find. 



\section{A* search}
...\\



\section{Results}
\section{Bibliography}

\end{document}